# Deformable Reference Detection

**Swin-Tiny + Deformable Attention for Multi-Template Single-Object Detection**

Target: **IoU > 0.90** | Params: **28M** | Memory: **FP16 ~5GB, FP32 ~10GB**

---

## ğŸ—ï¸ Architecture (Chi tiáº¿t)

```
ğŸ“¸ INPUT STAGE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Templates: 3Ã—(3,640,640)                       Search: (3,640,640) â”‚
â”‚      â†“                                                    â†“         â”‚
â”‚  â”Œâ”€Template 1â”€â”  â”Œâ”€Template 2â”€â”  â”Œâ”€Template 3â”€â”    â”Œâ”€Search Imageâ”€â” â”‚
â”‚  â”‚ (3,640,640)â”‚  â”‚ (3,640,640)â”‚  â”‚ (3,640,640)â”‚    â”‚ (3,640,640)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
ğŸ§  BACKBONE (Swin-Tiny - SHARED across all images)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Swin-Tiny Backbone (28M params, pretrained ImageNet)               â”‚
â”‚                                                                     â”‚
â”‚  Stage 1: (3,640,640) â†’ Skip (lightweight)                          â”‚
â”‚  Stage 2: (96,160,160) â†’ S2 Features (256,80,80)   [1/8 scale]      â”‚
â”‚  Stage 3: (192,80,80)  â†’ S3 Features (256,40,40)   [1/16 scale]     â”‚
â”‚  Stage 4: (384,40,40)  â†’ S4 Features (256,20,20)   [1/32 scale]     â”‚
â”‚                                                                     â”‚
â”‚  Output: Multi-scale features for Templates + Search                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
ğŸ¯ TEMPLATE ENCODING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Template Features â†’ Template Encoder                               â”‚
â”‚                                                                     â”‚
â”‚  Template 1: S2(256,80,80) + S3(256,40,40) + S4(256,20,20)          â”‚
â”‚              â†’ 3 scale tokens â†’ Global Average Pool â†’ 3 tokens      â”‚
â”‚                                                                     â”‚
â”‚  Template 2: Same process â†’ 3 tokens                                â”‚
â”‚  Template 3: Same process â†’ 3 tokens                                â”‚
â”‚                                                                     â”‚
â”‚  Total: 3 templates Ã— 3 scales = 9 Template Tokens (256 dim each)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
ğŸ”„ DEFORMABLE DECODER (6 layers)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input: 5 Learnable Queries (256 dim each)                          â”‚
â”‚       + 9 Template Tokens (256 dim each)                            â”‚
â”‚       + Search Features: S2(256,80,80), S3(256,40,40), S4(256,20,20)â”‚
â”‚                                                                     â”‚
â”‚  Each Decoder Layer:                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. Self-Attention (5 queries â†” 5 queries)                   â”‚    â”‚
â”‚  â”‚ 2. Template Cross-Attention (5 queries â†” 9 template tokens) â”‚    â”‚
â”‚  â”‚ 3. Deformable Search Attention:                             â”‚    â”‚
â”‚  â”‚    - Sample tá»« 3 levels (S2,S3,S4)                          â”‚    â”‚
â”‚  â”‚    - 4 points per level = 12 sampling points                â”‚    â”‚
â”‚  â”‚    - Learnable offsets + attention weights                  â”‚    â”‚
â”‚  â”‚ 4. FFN (256 â†’ 2048 â†’ 256)                                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              Ã—6 layers                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
ğŸ“Š PREDICTION HEADS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5 Query Features (256 dim each)                                    â”‚
â”‚                    â†“                                                â”‚
â”‚  â”Œâ”€Classification Headâ”€â”    â”Œâ”€Regression Headâ”€â”                     â”‚
â”‚  â”‚ Linear(256 â†’ 1)     â”‚    â”‚ MLP(256â†’256â†’4)  â”‚                     â”‚
â”‚  â”‚ â†’ 5 Logits          â”‚    â”‚ â†’ 5 BBoxes      â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                                                     â”‚
â”‚  Output: pred_logits(5,1) + pred_boxes(5,4)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
ğŸ¯ HUNGARIAN MATCHING
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5 Predictions vs 1 Ground Truth                                    â”‚
â”‚                                                                     â”‚
â”‚  Cost Matrix (5Ã—1):                                                 â”‚
â”‚  - Classification cost: Focal Loss weight                           â”‚
â”‚  - L1 BBox cost: |pred_box - gt_box|                                â”‚
â”‚  - GIoU cost: 1 - GIoU(pred_box, gt_box)                            â”‚
â”‚                                                                     â”‚
â”‚  Hungarian Algorithm â†’ Select Best Query                            â”‚
â”‚  Loss applied ONLY to selected query                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸƒâ€â™‚ï¸ INFERENCE: argmax(sigmoid(pred_logits)) â†’ Select highest confidence query
```

---

## ğŸš€ Quick Start

### Setup
```bash
conda activate aivn
pip install -r requirements.txt
```

### Training (Production Config)
```bash
# Actual config Ä‘ang dÃ¹ng (FP16 mixed precision)
python train.py \
  --data_dir refdet/retrieval_dataset_flat_zoomed/ \
  --output_dir drive/MyDrive/ZALO2025 \
  --checkpoint_path drive/MyDrive/AIVN/ZALOAI2025/last_epoch_2.pth \
  --mixed_precision \
  --img_size 640 \
  --num_queries 5 \
  --hidden_dim 256 \
  --num_decoder_layers 6 \
  --num_heads 8 \
  --dim_feedforward 2048 \
  --dropout 0.1 \
  --num_points 4 \
  --pretrained_backbone \
  --batch_size 16 \
  --epochs 10 \
  --lr 2e-4 \
  --min_lr 7e-5 \
  --lr_schedule cosine \
  --weight_decay 1e-4 \
  --augment_prob 0.1 \
  --workers 12 \
  --save_every 5 \
  --seed 42
```

### Key Features
- âš¡ **FP16 Mixed Precision**: `--mixed_precision` (2x memory, 1.5x speed)
- ğŸ”„ **Auto Checkpoint Conversion**: Load FP32 â†’ Auto convert FP16 â†’ Save FP16
- ğŸ¨ **Smart Augmentation**: Template clean, Search augmented (prob=0.1)
- ğŸ§  **Pretrained Backbone**: Swin-Tiny ImageNet weights

---

## ğŸ“Š Performance

| Metric | Value | Note |
|--------|--------|------|
| Target IoU | >0.90 | Production ready |
| Parameters | 28M | Swin-Tiny backbone |
| Memory (FP16) | ~5GB | With batch_size=16 |
| Speed | ~15 min/epoch | A100, optimized |
| Convergence | ~50 epochs | With pretrained backbone |

---

## ğŸ› ï¸ Critical Settings

```bash
--pretrained_backbone     # MUST use (IoU 0.9 vs 0.3 without)
--mixed_precision        # 50% memory reduction
--augment_prob 0.1       # Template stable, search augmented
--dim_feedforward 2048   # FFN expansion (vs default 1024)
--lr 2e-4               # Higher than default 1e-4
--min_lr 7e-5           # Cosine schedule floor
  --seed 42
```

### 4. Resume Training
```bash
python train.py \
  --data_dir data/ \
  --output_dir outputs/ \
  --checkpoint_path outputs/checkpoint_epoch_50.pth \
  --pretrained_backbone
```

### 5. Inference
```bash
python inference.py \
  --checkpoint outputs/best.pth \
  --data_dir data/ \
  --split test \
  --output predictions.json
```

---

## âš™ï¸ Data Augmentation (Optimized)

**Template: KHÃ”NG augment** (resize + normalize only)

**Search: Augment tá»‘i Æ°u** (prob=0.1)

| Type | Parameter | Range | Note |
|------|-----------|-------|------|
| Geometric | Rotation | Â±3Â° | Giáº£m tá»« Â±5Â° |
| | Flip H | 50% | - |
| | Scale | 0.93-1.07 | Tiny objects |
| | Translate | Â±3% | X, Y Ä‘á»™c láº­p |
| Color | Brightness | 0.75-1.25 | Tá»« 0.7-1.3 |
| | Contrast | 0.75-1.25 | Tá»« 0.7-1.3 |
| | Saturation | 0.8-1.2 | Tá»« 0.7-1.3 |
| | Hue | Â±0.03 | âš ï¸ Tá»« Â±0.05 |
**Status:** âœ… Production Ready | **License:** MIT

